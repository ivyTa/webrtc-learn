<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport"
          content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Document</title>
</head>
<body>

<span style="white-space:pre">		</span>
<audio controls autoplay></audio>
<input type="button" value="开始录音" onclick="startRecording()"/>
<input type="button" value="停止录音" onclick="stopRecord()"/>
<input type="button" value="播放录音" onclick="playRecord()"/>
</body>
<script>

  (function (window) {
    //兼容
    window.URL = window.URL || window.webkitURL;


    if (navigator.mediaDevices === undefined) {
      navigator.mediaDevices = {};
    }

    if (navigator.mediaDevices.getUserMedia === undefined) {
      navigator.mediaDevices.getUserMedia = function (constraints) {

        let getUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia;

        if (!getUserMedia) {
          return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
        }

        return new Promise(function (resolve, reject) {
          getUserMedia.call(navigator, constraints, resolve, reject);
        });
      }
    }

    let HZRecorder = function (stream, config) {
      config = config || {};
      config.sampleBits = config.sampleBits || 8;      //采样数位 8, 16
      config.sampleRate = config.sampleRate || (44100 / 6);   //采样率(1/6 44100)


      //创建一个音频环境对象
      let AudioContext = window.AudioContext || window.webkitAudioContext;
      let context = new AudioContext();

      //将声音输入这个对像
      // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaStreamSource
      // 创建一个新的MediaStreamAudioSourceNode 对象, 需要传入一个媒体流对象(MediaStream对象)(可以从 navigator.getUserMedia 获得MediaStream对象实例), 然后来自MediaStream的音频就可以被播放和操作。
      let audioInput = context.createMediaStreamSource(stream);

      //设置音量节点
      // https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/createGain
      // 创建一个GainNode,可用于控制的整体增益(或体积)音频图。
      let volume = context.createGain();
      audioInput.connect(volume);

      //创建缓存，用来缓存声音
      let bufferSize = 4096;

      // 创建声音的缓存节点，createScriptProcessor方法的
      // 第二个和第三个参数指的是输入和输出都是双声道。
      // https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor
      // 创建一个ScriptProcessorNode用于直接音频处理。
      let recorder = context.createScriptProcessor(bufferSize, 2, 2);

      let audioData = {
        size: 0,         //录音文件长度
        buffer: [],    //录音缓存
        inputSampleRate: context.sampleRate,    //输入采样率
        inputSampleBits: 16,      //输入采样数位 8, 16
        outputSampleRate: config.sampleRate,   //输出采样率
        oututSampleBits: config.sampleBits,      //输出采样数位 8, 16
        input: function (data) {
          this.buffer.push(new Float32Array(data));
          this.size += data.length;
        },
        compress: function () { //合并压缩
          //合并
          let data = new Float32Array(this.size);
          console.log('this.size', this.size);
          console.log('data', data);
          let offset = 0;
          for (let i = 0; i < this.buffer.length; i++) {
            data.set(this.buffer[i], offset);
            offset += this.buffer[i].length;
          }
          //压缩
          let compression = parseInt(this.inputSampleRate / this.outputSampleRate);
          let length = data.length / compression;
          let result = new Float32Array(length);
          let index = 0, j = 0;
          while (index < length) {
            result[index] = data[j];
            j += compression;
            index++;
          }
          console.log('result', result);
          return result;
        },
        encodeWAV: function () {
          let sampleRate = Math.min(this.inputSampleRate, this.outputSampleRate);
          let sampleBits = Math.min(this.inputSampleBits, this.oututSampleBits);
          let bytes = this.compress();
          let dataLength = bytes.length * (sampleBits / 8);
          let buffer = new ArrayBuffer(44 + dataLength);
          let data = new DataView(buffer);

          let channelCount = 1;//单声道
          let offset = 0;

          let writeString = function (str) {
            for (let i = 0; i < str.length; i++) {
              data.setUint8(offset + i, str.charCodeAt(i));
            }
          };

          // 资源交换文件标识符
          writeString('RIFF');
          offset += 4;
          // 下个地址开始到文件尾总字节数,即文件大小-8
          data.setUint32(offset, 36 + dataLength, true);
          offset += 4;
          // WAV文件标志
          writeString('WAVE');
          offset += 4;
          // 波形格式标志
          writeString('fmt ');
          offset += 4;
          // 过滤字节,一般为 0x10 = 16
          data.setUint32(offset, 16, true);
          offset += 4;
          // 格式类别 (PCM形式采样数据)
          data.setUint16(offset, 1, true);
          offset += 2;
          // 通道数
          data.setUint16(offset, channelCount, true);
          offset += 2;
          // 采样率,每秒样本数,表示每个通道的播放速度
          data.setUint32(offset, sampleRate, true);
          offset += 4;
          // 波形数据传输率 (每秒平均字节数) 单声道×每秒数据位数×每样本数据位/8
          data.setUint32(offset, channelCount * sampleRate * (sampleBits / 8), true);
          offset += 4;
          // 快数据调整数 采样一次占用字节数 单声道×每样本的数据位数/8
          data.setUint16(offset, channelCount * (sampleBits / 8), true);
          offset += 2;
          // 每样本数据位数
          data.setUint16(offset, sampleBits, true);
          offset += 2;
          // 数据标识符
          writeString('data');
          offset += 4;
          // 采样数据总数,即数据总大小-44
          data.setUint32(offset, dataLength, true);
          offset += 4;
          // 写入采样数据
          if (sampleBits === 8) {
            for (let i = 0; i < bytes.length; i++, offset++) {
              let s = Math.max(-1, Math.min(1, bytes[i]));
              let val = s < 0 ? s * 0x8000 : s * 0x7FFF;
              val = parseInt(255 / (65535 / (val + 32768)));
              data.setInt8(offset, val, true);
            }
          } else {
            for (let i = 0; i < bytes.length; i++, offset += 2) {
              let s = Math.max(-1, Math.min(1, bytes[i]));
              data.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
          }

          console.log('data===>', data);
          return new Blob([data], {type: 'audio/wav'});
        }
      };

      //开始录音
      this.start = function () {
        console.log('context.destination', context.destination);
        audioInput.connect(recorder);
        // 返回一个AudioDestinationNode代表上下文中的所有音频的最终目的地。它往往代表了一个实际的audio-rendering设备如你的设备的扬声器。
        // https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/destination
        recorder.connect(context.destination);
      };

      //停止
      this.stop = function () {
        recorder.disconnect();
      };

      //获取音频文件
      this.getBlob = function () {
        this.stop();
        return audioData.encodeWAV();
      };

      //回放
      this.play = function (audio) {
        let blobURL = window.URL.createObjectURL(this.getBlob());

        console.log('blobURL', blobURL);
        audio.src = blobURL;
      };

      //上传
      this.upload = function (url, callback) {
        let fd = new FormData();
        fd.append('audioData', this.getBlob());
        let xhr = new XMLHttpRequest();
        if (callback) {
          xhr.upload.addEventListener('progress', function (e) {
            callback('uploading', e);
          }, false);
          xhr.addEventListener('load', function (e) {
            callback('ok', e);
          }, false);
          xhr.addEventListener('error', function (e) {
            callback('error', e);
          }, false);
          xhr.addEventListener('abort', function (e) {
            callback('cancel', e);
          }, false);
        }
        xhr.open('POST', url);
        xhr.send(fd);
      };

      //音频采集
      recorder.onaudioprocess = function (e) {
        console.log('e.inputBuffer.getChannelData(0)', e.inputBuffer.getChannelData(0));
        audioData.input(e.inputBuffer.getChannelData(0));
        //record(e.inputBuffer.getChannelData(0));
      };

    };
    //抛出异常
    HZRecorder.throwError = function (message) {
      alert(message)
    };


    //是否支持录音
    HZRecorder.canRecording = (navigator.mediaDevices.getUserMedia != null);



    //获取录音机
    HZRecorder.get = function (callback, config) {
      if (callback) {
        if (navigator.mediaDevices.getUserMedia) {
          navigator.mediaDevices.getUserMedia({audio: true}).then((stream) => {
            console.log('stream===>', stream);
            let rec = new HZRecorder(stream, config);
            callback(rec);
          })
            .catch((error) => {
              switch (error.code || error.name) {
                case 'PERMISSION_DENIED':
                case 'PermissionDeniedError':
                  HZRecorder.throwError('用户拒绝提供信息。');
                  break;
                case 'NOT_SUPPORTED_ERROR':
                case 'NotSupportedError':
                  HZRecorder.throwError('<a href="http://www.it165.net/edu/ewl/" target="_blank" class="keylink">浏览器</a>不支持硬件设备。');
                  break;
                case 'MANDATORY_UNSATISFIED_ERROR':
                case 'MandatoryUnsatisfiedError':
                  HZRecorder.throwError('无法发现指定的硬件设备。');
                  break;
                default:
                  HZRecorder.throwError('无法打开麦克风。异常信息:' + (error.code || error.name));
                  break;
              }
            })
        } else {
          HZRecorder.throwErr('当前<a href="http://www.it165.net/edu/ewl/" target="_blank" class="keylink">浏览器</a>不支持录音功能。');
          return;
        }
      }
    };
    window.HZRecorder = HZRecorder;

  })(window);


  let recorder;
  let audio = document.querySelector('audio');


  function getTimes() {

    //获取录音时长
    let url = window.URL.createObjectURL(recorder.getBlob());
    //经测试，发现audio也可获取视频的时长
    let audioElement = new Audio(url);

    let duration;
    audioElement.addEventListener("loadedmetadata", function (_event) {
      duration = audioElement.duration;
      console.log(duration);
    });
  }

  function startRecording() {
    HZRecorder.get(function (rec) {
      recorder = rec;
      recorder.start();
    });
  }

  function stopRecord() {
    getTimes();
    recorder.stop();
  };

  function playRecord() {
    recorder.play(audio);
  };


</script>
</html>